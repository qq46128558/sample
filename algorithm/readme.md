## 时间复杂度

* n寸面包，每3天吃掉1寸，吃完要3n天，记作T(n)=3n
* n寸面包，每5天吃掉一半，剩1寸要5logn，记作T(n)=5logn
* n寸面包，每2天吃掉1个鸡腿，吃完鸡腿要2天，记作T(n)=2
* n寸面包，第1寸1天，第二个1寸2天，第三个1寸3天，吃完要1+2+3+...+n-1+n=0.5n^2+0.5n，记作T(n)=0.5n^2+0.5n

若存在函数f(n),使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于0的常数，则称f(n)是T(n)的同数量级函数。

记作T(n)=O(f(n))，称O(f(n))为算法的渐进时间复杂度，简称时间复杂度。

推导出时间复杂度的原则：

* 如果运行时间是常数量级，用常数1表示
* 只保留时间函数中的最高阶项
* 如果最高阶项存在，则省去最高阶项前面的系数

* T(n)=3n，时间复杂度为O(n)
* T(n)=5logn，O(logn)
* T(n)=2，O(1)
* T(n)=0.5n^2+0.5n，O(n^2)

* O(1)<O(logn)<O(n)<O(n^2)

## 快速排序

快速排序[O(nLogn)]是从冒泡排序[O(n^2)]演变而来的算法，但是比冒泡排序高效，使用了分治法。也属于交换排序。

冒泡排序在每一轮只把一个元素冒泡到数列的一端

快速排序在每一轮挑选一个基准元素，并让其他比它大的元素移动到数列一边，比他小的元素移动到数列另一边，从而把数列拆解成了两个部分。

* 挖坑法
* 指针交换法


## 如何判断一个数是否在40亿个整数中？

* 一个整数4个字节,一个字节8位(1111 1111)
* 4字节x8位=32位(32个1), 4294967295(2^32-1)
* 10亿字节(1,000,000,000byte)为1G
* 40亿个整数,则40亿x4字节=160亿字节,即需要16G
* 判断一个数存在不存在只有两个状态,所以可以用一个位来代表
	* bitmap算法(大数据算法,用位来表示状态)
	* 2^32=4294967296,所以可以申请2^32个位
	* 一个字节8位,2^32/8(2^3)=536870912字节(2^29),即约500M空间即可

## 如何实现可以获取最小值的栈？

* 我现在需要实现一个栈，这个栈除了可以进行普通的push、pop操作以外，还可以进行getMin的操作，getMin方法被调用后，会返回当前栈的最小值，你会怎么做呢？你可以假设栈里面存的都是int整数。
* 一个data栈,一个mins辅助栈
* mins栈存依次入栈的最小值的索引
	* 2 1 2 3 4 1 1 1 6 依次入栈
		* data: 2 1 2 3 4 1 1 1 6
		* mins: 0 1
* push(2)
	* data: 2
	* mins: 0
* push(1)
	* data: 2 1
	* mins: 0 1
* push(1)
	* data: 2 1 1
	* mins: 0 1
* pop()
	* data: 2 1
	* mins: 0 1 (索引为2,mins不动)
* getMin()
	* mins栈顶为1,找data索引1的值1返回

## 热搜排行榜原型

每个被搜索的词条都是一个结构体，所有的被搜索词条构成了一个结构体数组，也就是一个线性结构。被搜索词条这个结构体中有两个成员变量，一个是用于存放搜索次数的整形变量sum，sum要被赋初值为0；另一个是用于存放关键词的字符串key。

将每次用户的输入分成两种情况，第一种情况是之前已经被搜索过的关键词，第二种情况则是之前从来没有被搜索过的关键词。若是第一种情况则让该词条的搜索次数自加1；若是第二种情况则要将新的用户输入作为新词条存储到由被搜索词条构成的结构体数组中，并让该新词条的搜索次数自加1，此时该新词条的搜索次数由初始化后的0变为1。

运用选择排序法或者其他排序算法根据搜索次数由多到少将词条进行排序

## 如何通过编程解决华容道问题？

* 搜索(brute暴力搜索),可以进行搜索的方向

* 剪枝(不再去搜索一些明显不对的方向)

* 回溯(回退),当前面没有路的时候，我们就需要返回来，找到之前有可能出现岔路口的地方，再去下一个方向进行搜索

上面3个步骤是一个比较完整的搜索过程,空格在华容道中移动，就好像我在迷宫里走动一样，每次到一个新的状态，就有几个方向可以搜索，如果是之前碰到过的状态，那就不搜索;

走不通不一定是没路的时候,如果前面的路是之前走过的,也不应该再往前走了,应该回溯

**递归实现回溯**

“回溯”的过程有点像栈的操作。往前走一步就像是入栈，到了死胡同，要往回退，就像是出栈。这个过程确实是栈的过程，但是直接用栈的话，对于你刚刚接触搜索算法，可能编码比较难。其实你可以用递归来实现这个搜索过程. 其实递归在计算机内部也是栈来实现.

* 记录移动路径，其实就是在真正搜索之前，把方向记录下来，而搜索如果要返回了，则说明该次搜索已经结束，没有结果，应该把该记录去除。

* 堆栈溢出:步数太多内存不足. 可以判断一下，如果某条路走的步数超过100步，就不再走了，赶紧回退。

sample

~~~html
1 2 3
4 0 6
7 5 8
可以胜利,路径为:下 右
~~~

* 深搜: 深度优先搜索，会在一个方向一直搜下去，直到这条路走不通，才会考虑第二个方向。(深度优先过程实际上是通过一种递归的方式来进行实现的。)

* 广搜: 广度优先搜索，是先搜索每一个可行方向的第一步，然后再接着搜索每一个可行方向的第二步。以此类推。你可以认为有一波人在搜索,在每一个岔路口,都会分成多波在每一个方向分头行动进行搜索. **你可以将要搜索的初始状态加到一个队列里，然后每次从队列中取出一个状态，往可以前进的方向前进一步，然后再将该状态放到队列。利用队列先进先出的特点，就可以实现广搜的效果。**

## 什么是二叉堆？

是一种数据结构.二叉堆本质上是一种完全二叉树.分为:最大堆和最小堆.

* 最大堆任何一个父节点的值，都大于等于它左右孩子节点的值。

* 最小堆任何一个父节点的值，都小于等于它左右孩子节点的值。

* 二叉堆的根节点叫做堆顶。

* 最大堆和最小堆的特点，决定了在最大堆的堆顶是整个堆中的最大元素；最小堆的堆顶是整个堆中的最小元素。

* 堆的自我调整,对于二叉堆，如下有几种操作：(以最小堆为例)

	* 插入节点

		* 二叉堆的节点插入，插入位置是完全二叉树的最后一个位置。比如我们插入一个新节点，值是 0。

		* 这时候，我们让节点0的它的父节点5做比较，如果0小于5，则让新节点“上浮”，和父节点交换位置。

	* 删除节点

		* 二叉堆的节点删除过程和插入过程正好相反，所删除的是处于堆顶的节点。比如我们删除最小堆的堆顶节点1。

		* 这时候，为了维持完全二叉树的结构，我们把堆的最后一个节点10补到原本堆顶的位置。

		* 接下来我们让移动到堆顶的节点10和它的左右孩子进行比较，如果左右孩子中最小的一个（显然是节点2）比节点10小，那么让节点10“下沉”。

	* 构建二叉堆

		* 构建二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质上就是让 **所有非叶子节点依次下沉** 。

		* 非叶子节点: 有子节点的点

* 二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。
	
	* 数组中，在没有左右指针的情况下，如何定位到一个父节点的左孩子和右孩子呢？

	* 我们可以依靠数组下标来计算。

	* 假设父节点的下标是parent，那么它的左孩子下标就是 2*parent+1；它的右孩子下标就是  2*parent+2 。

## 既然最后都是有序序列，为什么还要分稳定和非稳定的排序呢？

笔试主要问是什么，而面试主要问为什么。

* 稳定排序就是相同的值, 排序后原位置的前后关系依然不变, 非稳定排序则不一定.

其实就是有两个排序关键字的时候，稳定排序可以让第一个关键字排序的结果服务于第二个关键字排序中数值相等的那些数。

* 比如我们班的同学，已经按照学号排好序了。现在要按照身高排序。如果是稳定排序排好之后，身高相同的同学，还是按照学号顺序的。

稳定排序保证两次排序结果相同

## 什么是桶排序？

算法题: 一个长度为20的double类型数组,取值范围从0 到 10,要求用最快的速度把这20个double类型元素从小到大进行排序.

先来回顾一下计数排序:计数排序需要根据原始数列的取值范围，创建一个统计数组，用来统计原始数列中每一个可能的整数值所出现的次数。原始数列中的整数值，和统计数组的下标是一一对应的，以数列的最小值作为偏移量。比如原始数列(95,94,91,98,99,90,99,93,91,92)的最小值是90， 那么整数95对应的统计数组下标就是 95-90 = 5。

桶排序:每一个桶（bucket）代表一个区间范围，里面可以承载一个或多个元素。

* (第一步求数列最大最小值)桶排序的第一步，就是创建这些桶，确定每一个桶的区间范围：我们这里创建的桶数量等于原始数列的元素数量，除了最后一个桶只包含数列最大值，前面各个桶的区间按照比例确定。

	* 区间跨度 = （最大值-最小值）/ （桶的数量 - 1）

* 第二步，遍历原始数列，把元素对号入座放入各个桶中：

* 第三步，每个桶内部的元素分别排序

* 第四步，遍历所有的桶，输出所有元素：到此为止，排序结束。

## 如何在500w个单词中统计特定前缀的单词有多少个？

题目：我有500w个单词，你帮忙设计一个数据结构来进行存储，存好之后，我有两个需求。
1、来了一个新的单词，需要判断是否在这500w个单词中
2、来了一个单词前缀，给出500w个单词中有多少个单词是该前缀

树形结构: 比如interest-ing,interest-ed 如果要找单词interest，那么就找根节点了，如果是找单词interesting，那么就从根节点往下走，再把沿路的字母们都拼起来就行了

为了统一成一棵树,可以弄一个空的根节点连接他们, 圆形节点是单词,方形节点是前缀

**遍历以前缀节点为根结点的一棵树，就能统计出前缀为inter的所有单词有多少个。**

**节点中增加一个变量用于计数，在添加节点的时候，就把相应的计数+1, 则统计更快**

> 这其实就是字典树的思想

> 标准的字典树是一个节点对应一个字母

自动补全控件,其实就可以用字典树来实现

## LRU 算法(least recently used最近最少使用)

LRU算法使用了哈希链表,在哈希链表当中，这些Key-Value不再是彼此无关的存在，而是被一个链条串了起来。每一个Key-Value都具有它的前驱Key-Value、后继Key-Value，就像双向链表中的节点一样。

LRU算法的基本思路:

* 1.假设我们使用哈希链表来缓存用户信息，目前缓存了4个用户，这4个用户是按照时间顺序依次从链表右端插入的。
* 2.此时，业务方访问用户5，由于哈希链表中没有用户5的数据，我们从数据库中读取出来，插入到缓存当中。这时候，链表中最右端是最新访问到的用户5，最左端是最近最少访问的用户1。
* 3.接下来，业务方访问用户2，哈希链表中存在用户2的数据，我们怎么做呢？我们把用户2从它的前驱节点和后继节点之间移除，重新插入到链表最右端。这时候，链表中最右端变成了最新访问到的用户2，最左端仍然是最近最少访问的用户1。
* 4.接下来，业务方请求修改用户4的信息。同样道理，我们把用户4从原来的位置移动到链表最右侧，并把用户信息的值更新。这时候，链表中最右端是最新访问到的用户4，最左端仍然是最近最少访问的用户1。
* 5.后来业务方换口味了，访问用户6，用户6在缓存里没有，需要插入到哈希链表。假设这时候缓存容量已经达到上限，必须先删除最近最少访问的数据，那么位于哈希链表最左端的用户1就会被删除掉，然后再把用户6插入到最右端。

以上，就是LRU算法的基本思路。

> redis底层也实现了类似于LRU的回收算法
